{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "osc_data_train = pd.read_csv('DATA/orange_small_churn_data.train')\n",
    "osc_labels_train = pd.read_csv('DATA/orange_small_churn_labels.train', header=None, names=['labels'])\n",
    "osc_data_label = pd.concat([osc_data_train, osc_labels_train], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с простого, но важного шага. Отделите небольшую выборку от существующих данных. Назовем её hold-out dataset. Эта выборка нужна для контроля качества решения: **она не должна использоваться вплоть до контроля качества решения**. Наличие такой выборки поможет убедиться, что в процессе моделирования не было допущено ошибок, не произошло переобучение. В качестве ответа загрузите полученный файл (или файлы, если вы работаете а данными и метками как с 2мя файлами)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_split = int((osc_data_label.shape[0]/4)*3)\n",
    "train = osc_data_label.iloc[:num_split, :]\n",
    "hold_out_dataset = osc_data_label.iloc[num_split:, :]\n",
    "\n",
    "columns = osc_data_label.columns\n",
    "\n",
    "categories = columns[190:len(columns)-1]\n",
    "\n",
    "train_categories = train[categories]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подумайте и предложите несколько способов (не менее 3х) обработки категориальных признаков, для того, чтобы их можно было использовать при построении модели. Обратите внимание на модуль sklearn.preprocessing. Начать поиски можно с sklearn.preprocessing.OneHotEncoder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LabelEncoder\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "train_categories_le = train_categories.copy()\n",
    "for (idx, column) in enumerate(categories):\n",
    "    train_categories_le[column] = labelencoder.fit_transform(train_categories_le[column].fillna('0'))\n",
    "\n",
    "# OneHotEncoder\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder() \n",
    "train_categories_ohe = train_categories.copy()\n",
    "train_categories_ohe = ohe.fit_transform(train_categories.fillna('0'))\n",
    "\n",
    "# BinaryEncoder\n",
    "\n",
    "train_categories_ce = train_categories.copy()\n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "encoder = ce.BinaryEncoder()\n",
    "train_categories_binary = encoder.fit_transform(train_categories.fillna('0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подумайте, с помощью какой метрики качества лучше всего оценивать качество будущей модели, какой будет ключевая метрика качества? Поясните свой выбор. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Так как квалификация бинарная и данные могут не совмпадать по размеру, то буду использовать AUC-ROC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
